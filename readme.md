# 美团酒店评论抓取和情感分析

​	作为一个练手项目，协助笔者本人一位文科同学做数据分析，作为课程论文。文科生做数据分析项目，拿一堆的编程框架和机器学习的数学公式，这是很不适合的；因此我的思路是尽量目的明确，用的工具简单、明了、易上手。用到的工具有**八爪鱼、pandas、jieba分词、SnowNLP自然语言处理库**。

​	我选用八爪鱼这类爬虫工具来爬取数据，省去了用python来写爬虫的繁琐过程，用python来写这个爬虫有点杀鸡用牛刀。

​	数据来了之后，首先第一步就是对数据进行清洗、查重，除去那些没有意义的评论。（这个是做数据科学处理的必备项目，不要小看这一步，数据处理的好与不好，对后面的分析流程很关键，甚至能决定你模型的好坏，我本科那会刚开始做数学建模的时候，没有意识到这个问题，吃了很多亏）。

​	做中文文本分析的同学，对jieba这个库来说应该不陌生，算是目前做中文分词作的最好的一个库了。我们直接调用jiba库的api进行分词，调用tf-idf或者TextRank算法都可以实现文摘提取，具体用那种算法，根据实际情况认定。在这个分析过程中，我觉得TextRank算法的记过更为准确。

​	情感分析方面，是属于NLP领域的内容，从原理上来说还是蛮难的，设计到词向量以及语义分析等一系列理论和复杂的数学公式，这个显然不是本项目的重点。从github上查了几个做类似的工作用到了SnowNLP这个NLP的库（https://github.com/isnowfy/snownlp）。这个库简单易用，集合了如下功能：

- 中文分词（[Character-Based Generative Model](http://aclweb.org/anthology//Y/Y09/Y09-2047.pdf)）

- 词性标注（[TnT](http://aclweb.org/anthology//A/A00/A00-1031.pdf) 3-gram 隐马）

- 情感分析（现在训练数据主要是买卖东西时的评价，所以对其他的一些可能效果不是很好，待解决）

- 文本分类（Naive Bayes）

- 转换成拼音（Trie树实现的最大匹配）

- 繁体转简体（Trie树实现的最大匹配）

- 提取文本关键词（[TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)算法）

- 提取文本摘要（[TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)算法）

- tf，idf

- Tokenization（分割成句子）

- 文本相似（[BM25](http://en.wikipedia.org/wiki/Okapi_BM25)）

- 支持python3（感谢[erning](https://github.com/erning)）

  使用下来发现，这个库的分词效果没有jieba做到好（最好的中文分词库过然名不虚传），这个库的情感分析还是蛮不错的，而且官方说明了，原始的库就是基于淘宝消费评论来训练这个情感模型的，所以还是比较适合来做美团评论的情感分析。如果想用这个库来做其他的情感分析，可能不是很合适，这个库很友好也给出了基于你自己的数据来训练情感分类模型，这就需要你有很多做好情感标注的文本数据了（一般人做不来额~~）。

  SnowNLP做情感分析的tips：

  

  - 要先做好数据清洗再开始情感分析，不要让离谱的样本参与情感分析
  - 对于长文本的情感分析容易出现分析的结果不正确，这时候可以先对文本提取摘要再进行情感分析，会准确很多。具体的过程参看项目的jupyter notebook文件



​	